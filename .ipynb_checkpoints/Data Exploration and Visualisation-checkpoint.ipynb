{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Data Exploration and Visualisation\n",
    "\n",
    "### Part One : Using How2 Dataset for YouTube videos IDs, transcriptions and description summaries. \n",
    "\n",
    "* Construct databases of video transcriptions and human made descriptions\n",
    "* Also, download audios of 400 videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dayangraham/opt/anaconda3/envs/FYPenv/lib/python3.7/site-packages/ipykernel_launcher.py:9: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset into a pandas data frame\n",
    "# Load the descriptions into a pandas data frame\n",
    "# Load the transcriptions into into a pandas data frame \n",
    "desctable = pd.read_csv('speech_data/text/sum_cv/desc.tok.txt', header=None, skipinitialspace=True, names=[\"a\"])\n",
    "desctable.head()\n",
    "filename = 'speech_data/text/sum_cv/tran.tok.txt'\n",
    "with open(filename, 'r') as f:\n",
    "    data = f.read().replace('\\n','%%%')\n",
    "trantable = pd.read_csv(pd.compat.StringIO(data), sep=\"%%%\", header=None)\n",
    "trantable = trantable.T\n",
    "trantable.drop(trantable.tail(1).index,inplace=True)\n",
    "trantable.columns=['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split id and description\n",
    "desctable['id'] = desctable.apply(lambda row: str(row.a).split(\" \")[0], axis = 1) \n",
    "desctable['desc'] = desctable.apply(lambda row: ' '.join(str(row.a).split(\" \")[1:]), axis = 1) \n",
    "desctable.drop('a',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split id and transcription\n",
    "trantable['id'] = trantable.apply(lambda row: row.a.split(\" \")[0], axis = 1) \n",
    "trantable['tran'] = trantable.apply(lambda row: ' '.join(row.a.split(\" \")[1:]), axis = 1) \n",
    "trantable.drop('a',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>desc</th>\n",
       "      <th>tran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-xd1aAlPXqs</td>\n",
       "      <td>learn the sivananda yoga single right leg rais...</td>\n",
       "      <td>after you 've done at least six to twelve roun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KtMjOT6fDrw</td>\n",
       "      <td>learn how to apply hanger hooks for your woodc...</td>\n",
       "      <td>on behalf of expert village , my name is husai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ehbFyYlcEhc</td>\n",
       "      <td>learn about how hand washing can help prevent ...</td>\n",
       "      <td>hi ! this is david jackel on behalf of expert ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lcw8f2od6z8</td>\n",
       "      <td>how to julienne cucumbers to make kimchi for k...</td>\n",
       "      <td>the other way we can do cucumbers which is als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G-VRHmkiqtc</td>\n",
       "      <td>in order to put photographic emulsion on water...</td>\n",
       "      <td>my name is anthony maddaloni and i 'm going to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               desc  \\\n",
       "0  -xd1aAlPXqs  learn the sivananda yoga single right leg rais...   \n",
       "1  KtMjOT6fDrw  learn how to apply hanger hooks for your woodc...   \n",
       "2  ehbFyYlcEhc  learn about how hand washing can help prevent ...   \n",
       "3  lcw8f2od6z8  how to julienne cucumbers to make kimchi for k...   \n",
       "4  G-VRHmkiqtc  in order to put photographic emulsion on water...   \n",
       "\n",
       "                                                tran  \n",
       "0  after you 've done at least six to twelve roun...  \n",
       "1  on behalf of expert village , my name is husai...  \n",
       "2  hi ! this is david jackel on behalf of expert ...  \n",
       "3  the other way we can do cucumbers which is als...  \n",
       "4  my name is anthony maddaloni and i 'm going to...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join tables on ID to create a single table \n",
    "conctable = pd.merge(desctable,trantable,on=\"id\")\n",
    "conctable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install dependencies to get audio from YouTube\n",
    "# !pip -q install wget youtube-dl wget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Take the first 400 YouTube video IDs\n",
    "# youtube_ids = conctable['id'].tolist()\n",
    "# shortlist = youtube_ids[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop over the 400 YouTube videos\n",
    "# # Save each video's audio as 8000Hz wav\n",
    "# for YOUTUBE_ID in shortlist:\n",
    "#     !youtube-dl --extract-audio --audio-format wav --quiet --output \"{YOUTUBE_ID}_FULL.%(ext)s\" https://www.youtube.com/watch\\?v\\={YOUTUBE_ID}\n",
    "#     !ffmpeg -loglevel panic -y -i {YOUTUBE_ID}_FULL.wav -acodec pcm_s16le -ac 1 -ar 8000 {YOUTUBE_ID}.wav\n",
    "#     !rm {YOUTUBE_ID}_FULL.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge \n",
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploretable = conctable.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploretable.loc[:,'intersection'] = exploretable.apply(lambda row: [value for value in row.desc.split(\" \") if value in row.tran.split(\" \")] , axis=1)\n",
    "exploretable.loc[:,'descnottran'] = exploretable.apply(lambda row: [value for value in row.desc.split(\" \") if value not in row.tran.split(\" \")] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploretable['rouge1-f'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-1']['f'], axis=1)\n",
    "exploretable['rouge1-r'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-1']['r'], axis=1)\n",
    "exploretable['rouge1-p'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-1']['p'], axis=1)\n",
    "exploretable['rouge2-f'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-2']['f'], axis=1)\n",
    "exploretable['rouge2-r'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-2']['r'], axis=1)\n",
    "exploretable['rouge2-p'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-2']['p'], axis=1)\n",
    "exploretable['rougel-f'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-l']['f'], axis=1)\n",
    "exploretable['rougel-r'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-l']['r'], axis=1)\n",
    "exploretable['rougel-p'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-l']['p'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>desc</th>\n",
       "      <th>tran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-xd1aAlPXqs</td>\n",
       "      <td>learn the sivananda yoga single right leg rais...</td>\n",
       "      <td>after you 've done at least six to twelve roun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               desc  \\\n",
       "0  -xd1aAlPXqs  learn the sivananda yoga single right leg rais...   \n",
       "\n",
       "                                                tran  \n",
       "0  after you 've done at least six to twelve roun...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploretable.head(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alignment of transcription to audio\n",
    "\n",
    "# Define imports for Kaldi Alignment\n",
    "from kaldi.alignment import NnetAligner\n",
    "from kaldi.fstext import SymbolTable\n",
    "from kaldi.lat.align import WordBoundaryInfoNewOpts, WordBoundaryInfo\n",
    "from kaldi.nnet3 import NnetSimpleComputationOptions\n",
    "from kaldi.util.table import SequentialMatrixReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspire_alignment():\n",
    "    # Construct aligner\n",
    "    decodable_opts = NnetSimpleComputationOptions()\n",
    "    decodable_opts.acoustic_scale = 1.0\n",
    "    decodable_opts.frames_per_chunk = 150\n",
    "    aligner = NnetAligner.from_files(\n",
    "        \"exp/tdnn_7b_chain_online/final.mdl\",\n",
    "        \"exp/tdnn_7b_chain_online/tree\",\n",
    "        \"data/lang/L.fst\",\n",
    "        \"data/lang/words.txt\",\n",
    "        \"data/lang/phones/disambig.int\",\n",
    "        decodable_opts=decodable_opts)\n",
    "    phones = SymbolTable.read_text(\"data/lang/phones.txt\")\n",
    "    wb_info = WordBoundaryInfo.from_file(WordBoundaryInfoNewOpts(),\n",
    "                                         \"data/lang/phones/word_boundary.int\")\n",
    "\n",
    "    # Define feature pipelines as Kaldi rspecifiers\n",
    "    feats_rspec = (\n",
    "        \"ark:compute-mfcc-feats --config=conf/mfcc_hires.conf scp:data/test/wav.scp ark:- |\"\n",
    "    )\n",
    "    ivectors_rspec = (\n",
    "        \"ark:compute-mfcc-feats --config=conf/mfcc_hires.conf scp:data/test/wav.scp ark:- |\"\n",
    "        \"ivector-extract-online2 --config=conf/ivector_extractor.conf ark:data/test/spk2utt ark:- ark:- |\"\n",
    "    )\n",
    "\n",
    "    # Align wav files\n",
    "    with SequentialMatrixReader(feats_rspec) as f, \\\n",
    "         SequentialMatrixReader(ivectors_rspec) as i, \\\n",
    "         open(\"data/test/text\",\"r\") as t:\n",
    "        for (fkey, feats), (ikey, ivectors), line in zip(f, i, t):\n",
    "            tkey, text = line.strip().split(None, 1)\n",
    "            assert(fkey == ikey == tkey)\n",
    "            out = aligner.align((feats, ivectors), text)\n",
    "            phone_alignment = aligner.to_phone_alignment(out[\"alignment\"], phones)\n",
    "            word_alignment = aligner.to_word_alignment(out[\"best_path\"], wb_info)\n",
    "\n",
    "            print(f\"The Input Text: {text}\")\n",
    "    print(f\"The word alignment: {word_alignment}\")\n",
    "#     return (text,word_alignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File structure within the /data folder is as follows :\n",
    "-    /lang\n",
    "-    /test\n",
    "-        spk2utt - maps speakers to utterances? just repeat double unique id eg utt1 utt1\n",
    "-        text - transcription for each utterance on each line \n",
    "-        utt1.wav\n",
    "-        wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'word_alignment' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-b71ac0c94cd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ensure that you have run alignment_dependencies/path.sh in order to add Kaldi to the PATH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maspire_alignment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-aa3d03b7e6e7>\u001b[0m in \u001b[0;36maspire_alignment\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The Input Text: {text}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The word alignment: {word_alignment}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;31m#     return (text,word_alignment)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'word_alignment' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Ensure that you have run alignment_dependencies/path.sh in order to add Kaldi to the PATH\n",
    "aspire_alignment();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAlignmentDeps(table):\n",
    "    tranlist = table['tran'].tolist()\n",
    "    idlist = table['id'].tolist()\n",
    "#generate spk2utt \n",
    "    with open(\"spk2utt\", 'w') as f:\n",
    "        for id in idlist:\n",
    "            print(f\"{id} {id}\", file=f)\n",
    "#generate text \n",
    "# BE SURE TO RENAME 'test' to 'text' !!\n",
    "    with open(\"test\", 'w') as f:\n",
    "        for index, id in enumerate(idlist):\n",
    "            tran = tranlist[index]\n",
    "            print(f\"{id} {tran}\", file=f)\n",
    "#generate wav.scp \n",
    "    with open(\"wav.scp\", 'w') as f:\n",
    "        for id in idlist:\n",
    "            print(f\"{id}  ../../speech_audios/{id}.wav\", file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateAlignmentDeps(exploretable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
