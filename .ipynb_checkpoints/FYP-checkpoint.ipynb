{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Towards abstractive audio-to-audio summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thread 0 : Trimming Pauses and non-vocal activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment and playback using PyKaldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source ./path.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-16 17:57:51--  https://lowerquality.com/gentle/kaldi-models-0.03.zip\n",
      "Resolving lowerquality.com (lowerquality.com)... 82.221.106.101\n",
      "Connecting to lowerquality.com (lowerquality.com)|82.221.106.101|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 161246499 (154M) [application/zip]\n",
      "Saving to: ‘kaldi-models-0.03.zip’\n",
      "\n",
      "kaldi-models-0.03.z  13%[=>                  ]  20.18M  3.52MB/s    eta 41s    ^C\n"
     ]
    }
   ],
   "source": [
    "!./models.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define imports for Kaldi Alignment\n",
    "from kaldi.alignment import NnetAligner\n",
    "from kaldi.fstext import SymbolTable\n",
    "from kaldi.lat.align import WordBoundaryInfoNewOpts, WordBoundaryInfo\n",
    "from kaldi.nnet3 import NnetSimpleComputationOptions\n",
    "from kaldi.util.table import SequentialMatrixReader\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspire_alignment():\n",
    "    # Construct aligner\n",
    "    decodable_opts = NnetSimpleComputationOptions()\n",
    "    decodable_opts.acoustic_scale = 1.0\n",
    "    decodable_opts.frame_subsampling_factor = 0.1\n",
    "    decodable_opts.frames_per_chunk = 150\n",
    "    aligner = NnetAligner.from_files(\n",
    "        \"exp/tdnn_7b_chain_online/final.mdl\",\n",
    "        \"exp/tdnn_7b_chain_online/tree\",\n",
    "        \"data/lang/L.fst\",\n",
    "        \"data/lang/words.txt\",\n",
    "        \"data/lang/phones/disambig.int\",\n",
    "        decodable_opts=decodable_opts)\n",
    "    phones = SymbolTable.read_text(\"data/lang/phones.txt\")\n",
    "    wb_info = WordBoundaryInfo.from_file(WordBoundaryInfoNewOpts(),\n",
    "                                         \"data/lang/phones/word_boundary.int\")\n",
    "\n",
    "    # Define feature pipelines as Kaldi rspecifiers\n",
    "    feats_rspec = (\n",
    "        \"ark:compute-mfcc-feats --config=conf/mfcc_hires.conf scp:data/test/wav.scp ark:- |\"\n",
    "    )\n",
    "    ivectors_rspec = (\n",
    "        \"ark:compute-mfcc-feats --config=conf/mfcc_hires.conf scp:data/test/wav.scp ark:- |\"\n",
    "        \"ivector-extract-online2 --config=conf/ivector_extractor.conf ark:data/test/spk2utt ark:- ark:- |\"\n",
    "    )\n",
    "\n",
    "    # Align wav files\n",
    "    with SequentialMatrixReader(feats_rspec) as f, \\\n",
    "         SequentialMatrixReader(ivectors_rspec) as i, \\\n",
    "         open(\"data/test/text\",\"r\") as t:\n",
    "        for (fkey, feats), (ikey, ivectors), line in zip(f, i, t):\n",
    "            tkey, text = line.strip().split(None, 1)\n",
    "            assert(fkey == ikey == tkey)\n",
    "            out = aligner.align((feats, ivectors), text)\n",
    "            phone_alignment = aligner.to_phone_alignment(out[\"alignment\"], phones)\n",
    "            word_alignment = aligner.to_word_alignment(out[\"best_path\"], wb_info)\n",
    "\n",
    "            print(f\"The Input Text: {text}\")\n",
    "#         print(f\"The phoneme alignment: {phone_alignment}\")\n",
    "    print(f\"The word alignment: {word_alignment}\")\n",
    "#     return (text,word_alignment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Input Text: one two three four five six seven eight\n",
      "The word alignment: [('<eps>', 0, 121), ('one', 121, 41), ('<eps>', 162, 4), ('two', 166, 30), ('<eps>', 196, 4), ('three', 200, 39), ('<eps>', 239, 1), ('four', 240, 52), ('five', 292, 41), ('six', 333, 33), ('seven', 366, 47), ('<eps>', 413, 16), ('eight', 429, 28), ('<eps>', 457, 155)]\n"
     ]
    }
   ],
   "source": [
    "aspire_alignment();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playback(play_original, word_spacing,buffer):\n",
    "    originalutterance = AudioSegment.from_wav(\"./data/test/utt1.wav\")\n",
    "    silence = AudioSegment.silent(duration=word_spacing)\n",
    "    if play_original:\n",
    "        play(originalutterance)\n",
    "    for word in word_alignment:\n",
    "        if (word[0] != '<eps>'):\n",
    "            start_time = word[1]*10-buffer\n",
    "            end_time = start_time + word[2]*10+buffer\n",
    "            print(word[0])\n",
    "            snippet = originalutterance[start_time:end_time]\n",
    "            padded_snippet = silence.append(snippet.append(silence, crossfade=word_spacing/2),crossfade=word_spacing/2)\n",
    "            play(padded_snippet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one\n",
      "two\n",
      "three\n",
      "four\n",
      "five\n",
      "six\n",
      "seven\n",
      "eight\n"
     ]
    }
   ],
   "source": [
    "playback(True,50,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6144"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(originalutterance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
