{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Data Exploration and Visualisation\n",
    "\n",
    "### Part One : Using How2 Dataset for YouTube videos IDs, transcriptions and description summaries. \n",
    "\n",
    "* Construct databases of video transcriptions and human made descriptions\n",
    "* Also, download audios of 400 videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dayangraham/opt/anaconda3/envs/FYPenv/lib/python3.7/site-packages/ipykernel_launcher.py:9: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset into a pandas data frame\n",
    "# Load the descriptions into a pandas data frame\n",
    "# Load the transcriptions into into a pandas data frame \n",
    "desctable = pd.read_csv('speech_data/text/sum_cv/desc.tok.txt', header=None, skipinitialspace=True, names=[\"a\"])\n",
    "desctable.head()\n",
    "filename = 'speech_data/text/sum_cv/tran.tok.txt'\n",
    "with open(filename, 'r') as f:\n",
    "    data = f.read().replace('\\n','%%%')\n",
    "trantable = pd.read_csv(pd.compat.StringIO(data), sep=\"%%%\", header=None)\n",
    "trantable = trantable.T\n",
    "trantable.drop(trantable.tail(1).index,inplace=True)\n",
    "trantable.columns=['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split id and description\n",
    "desctable['id'] = desctable.apply(lambda row: str(row.a).split(\" \")[0], axis = 1) \n",
    "desctable['desc'] = desctable.apply(lambda row: ' '.join(str(row.a).split(\" \")[1:]), axis = 1) \n",
    "desctable.drop('a',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split id and transcription\n",
    "trantable['id'] = trantable.apply(lambda row: row.a.split(\" \")[0], axis = 1) \n",
    "trantable['tran'] = trantable.apply(lambda row: ' '.join(row.a.split(\" \")[1:]), axis = 1) \n",
    "trantable.drop('a',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>desc</th>\n",
       "      <th>tran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-xd1aAlPXqs</td>\n",
       "      <td>learn the sivananda yoga single right leg rais...</td>\n",
       "      <td>after you 've done at least six to twelve roun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KtMjOT6fDrw</td>\n",
       "      <td>learn how to apply hanger hooks for your woodc...</td>\n",
       "      <td>on behalf of expert village , my name is husai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ehbFyYlcEhc</td>\n",
       "      <td>learn about how hand washing can help prevent ...</td>\n",
       "      <td>hi ! this is david jackel on behalf of expert ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lcw8f2od6z8</td>\n",
       "      <td>how to julienne cucumbers to make kimchi for k...</td>\n",
       "      <td>the other way we can do cucumbers which is als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G-VRHmkiqtc</td>\n",
       "      <td>in order to put photographic emulsion on water...</td>\n",
       "      <td>my name is anthony maddaloni and i 'm going to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               desc  \\\n",
       "0  -xd1aAlPXqs  learn the sivananda yoga single right leg rais...   \n",
       "1  KtMjOT6fDrw  learn how to apply hanger hooks for your woodc...   \n",
       "2  ehbFyYlcEhc  learn about how hand washing can help prevent ...   \n",
       "3  lcw8f2od6z8  how to julienne cucumbers to make kimchi for k...   \n",
       "4  G-VRHmkiqtc  in order to put photographic emulsion on water...   \n",
       "\n",
       "                                                tran  \n",
       "0  after you 've done at least six to twelve roun...  \n",
       "1  on behalf of expert village , my name is husai...  \n",
       "2  hi ! this is david jackel on behalf of expert ...  \n",
       "3  the other way we can do cucumbers which is als...  \n",
       "4  my name is anthony maddaloni and i 'm going to...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join tables on ID to create a single table \n",
    "conctable = pd.merge(desctable,trantable,on=\"id\")\n",
    "conctable.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install dependencies to get audio from YouTube\n",
    "# !pip -q install wget youtube-dl wget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Take the first 400 YouTube video IDs\n",
    "# youtube_ids = conctable['id'].tolist()\n",
    "# shortlist = youtube_ids[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop over the 400 YouTube videos\n",
    "# # Save each video's audio as 8000Hz wav\n",
    "# for YOUTUBE_ID in shortlist:\n",
    "#     !youtube-dl --extract-audio --audio-format wav --quiet --output \"{YOUTUBE_ID}_FULL.%(ext)s\" https://www.youtube.com/watch\\?v\\={YOUTUBE_ID}\n",
    "#     !ffmpeg -loglevel panic -y -i {YOUTUBE_ID}_FULL.wav -acodec pcm_s16le -ac 1 -ar 8000 {YOUTUBE_ID}.wav\n",
    "#     !rm {YOUTUBE_ID}_FULL.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge \n",
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploretable = conctable.iloc[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploretable.loc[:,'intersection'] = exploretable.apply(lambda row: [value for value in row.desc.split(\" \") if value in row.tran.split(\" \")] , axis=1)\n",
    "exploretable.loc[:,'descnottran'] = exploretable.apply(lambda row: [value for value in row.desc.split(\" \") if value not in row.tran.split(\" \")] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploretable['rouge1-f'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-1']['f'], axis=1)\n",
    "exploretable['rouge1-r'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-1']['r'], axis=1)\n",
    "exploretable['rouge1-p'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-1']['p'], axis=1)\n",
    "exploretable['rouge2-f'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-2']['f'], axis=1)\n",
    "exploretable['rouge2-r'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-2']['r'], axis=1)\n",
    "exploretable['rouge2-p'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-2']['p'], axis=1)\n",
    "exploretable['rougel-f'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-l']['f'], axis=1)\n",
    "exploretable['rougel-r'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-l']['r'], axis=1)\n",
    "exploretable['rougel-p'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-l']['p'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>desc</th>\n",
       "      <th>tran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KtMjOT6fDrw</td>\n",
       "      <td>learn how to apply hanger hooks for your woodc...</td>\n",
       "      <td>on behalf of expert village , my name is husai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               desc  \\\n",
       "1  KtMjOT6fDrw  learn how to apply hanger hooks for your woodc...   \n",
       "\n",
       "                                                tran  \n",
       "1  on behalf of expert village , my name is husai...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploretable.head(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alignment of transcription to audio\n",
    "\n",
    "# Define imports for Kaldi Alignment\n",
    "from kaldi.alignment import NnetAligner\n",
    "from kaldi.fstext import SymbolTable\n",
    "from kaldi.lat.align import WordBoundaryInfoNewOpts, WordBoundaryInfo\n",
    "from kaldi.nnet3 import NnetSimpleComputationOptions\n",
    "from kaldi.util.table import SequentialMatrixReader\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspire_alignment():\n",
    "    # Construct aligner\n",
    "    decodable_opts = NnetSimpleComputationOptions()\n",
    "    decodable_opts.acoustic_scale = 1.0\n",
    "    decodable_opts.frames_per_chunk = 150\n",
    "    aligner = NnetAligner.from_files(\n",
    "        \"exp/tdnn_7b_chain_online/final.mdl\",\n",
    "        \"exp/tdnn_7b_chain_online/tree\",\n",
    "        \"data/lang/L.fst\",\n",
    "        \"data/lang/words.txt\",\n",
    "        \"data/lang/phones/disambig.int\",\n",
    "        decodable_opts=decodable_opts)\n",
    "    phones = SymbolTable.read_text(\"data/lang/phones.txt\")\n",
    "    wb_info = WordBoundaryInfo.from_file(WordBoundaryInfoNewOpts(),\n",
    "                                         \"data/lang/phones/word_boundary.int\")\n",
    "\n",
    "    # Define feature pipelines as Kaldi rspecifiers\n",
    "    feats_rspec = (\n",
    "        \"ark:compute-mfcc-feats --config=conf/mfcc_hires.conf scp:data/test/wav.scp ark:- |\"\n",
    "    )\n",
    "    ivectors_rspec = (\n",
    "        \"ark:compute-mfcc-feats --config=conf/mfcc_hires.conf scp:data/test/wav.scp ark:- |\"\n",
    "        \"ivector-extract-online2 --config=conf/ivector_extractor.conf ark:data/test/spk2utt ark:- ark:- |\"\n",
    "    )\n",
    "\n",
    "    # Align wav files\n",
    "    with SequentialMatrixReader(feats_rspec) as f, \\\n",
    "         SequentialMatrixReader(ivectors_rspec) as i, \\\n",
    "         open(\"data/test/text\",\"r\") as t:\n",
    "        for (fkey, feats), (ikey, ivectors), line in zip(f, i, t):\n",
    "            tkey, text = line.strip().split(None, 1)\n",
    "            text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "            assert(fkey == ikey == tkey)\n",
    "            out = aligner.align((feats, ivectors), text)\n",
    "            phone_alignment = aligner.to_phone_alignment(out[\"alignment\"], phones)\n",
    "            word_alignment = aligner.to_word_alignment(out[\"best_path\"], wb_info)\n",
    "\n",
    "            print(f\"The Input Text: {text}\")\n",
    "    print(f\"The word alignment: {word_alignment}\")\n",
    "#     return (text,word_alignment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File structure within the /data folder is as follows :\n",
    "-    /lang\n",
    "-    /test\n",
    "-        spk2utt - maps speakers to utterances? just repeat double unique id eg utt1 utt1\n",
    "-        text - transcription for each utterance on each line \n",
    "-        utt1.wav\n",
    "-        wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Input Text: on behalf of expert village  my name is husain abdul alim and i am here to tell you all about wood carving  hooks  all kinds of hooks  and we have got a hook spotter cause some of this wood is kind of hard  kind of hard  kind of hard  no hook on my potential piece but we are going to get one on there sooner than later  we have to think about how that is going to hang  right about there  okay  okay and it needs another wire on it and we need another little wire to put up  you can hang on your wall  make a nice little circle inside my screw eye  okay  now it is ready to be hung  now it is ready to be hung \n",
      "The word alignment: [('<eps>', 0, 74), ('on', 74, 19), ('behalf', 93, 40), ('of', 133, 10), ('<eps>', 143, 18), ('expert', 161, 58), ('<eps>', 219, 22), ('village', 241, 69), ('<eps>', 310, 46), ('my', 356, 20), ('name', 376, 20), ('is', 396, 14), ('<eps>', 410, 37), (\"a's\", 447, 16), ('abdul', 463, 51), (\"a's\", 514, 37), ('<eps>', 551, 11), ('and', 562, 17), ('i', 579, 3), ('am', 582, 13), ('here', 595, 22), ('to', 617, 12), ('tell', 629, 15), ('you', 644, 19), ('all', 663, 22), ('about', 685, 29), ('wood', 714, 19), ('carving', 733, 40), ('<eps>', 773, 149), ('hooks', 922, 44), ('<eps>', 966, 142), ('all', 1108, 43), ('<eps>', 1151, 1), ('kinds', 1152, 36), ('of', 1188, 12), ('hooks', 1200, 43), ('<eps>', 1243, 549), ('and', 1792, 26), ('we', 1818, 7), ('have', 1825, 5), ('got', 1830, 18), ('a', 1848, 8), ('hook', 1856, 29), ('<eps>', 1885, 70), ('spotter', 1955, 50), ('<eps>', 2005, 150), ('cause', 2155, 4), ('<eps>', 2159, 3), ('some', 2162, 21), ('of', 2183, 7), ('this', 2190, 16), ('wood', 2206, 16), ('is', 2222, 13), ('kind', 2235, 24), ('of', 2259, 2), ('<eps>', 2261, 14), ('hard', 2275, 42), ('<eps>', 2317, 1), ('kind', 2318, 20), ('of', 2338, 12), ('hard', 2350, 37), ('kind', 2387, 20), ('of', 2407, 8), ('hard', 2415, 18), ('<eps>', 2433, 1), ('no', 2434, 19), ('hook', 2453, 24), ('on', 2477, 15), ('my', 2492, 37), ('<eps>', 2529, 78), ('potential', 2607, 48), ('piece', 2655, 36), ('but', 2691, 26), ('<eps>', 2717, 100), ('we', 2817, 8), ('are', 2825, 2), ('going', 2827, 13), ('to', 2840, 8), ('get', 2848, 17), ('one', 2865, 18), ('on', 2883, 14), ('there', 2897, 15), ('<eps>', 2912, 1), ('sooner', 2913, 31), ('than', 2944, 16), ('later', 2960, 36), ('<eps>', 2996, 116), ('we', 3112, 7), ('have', 3119, 11), ('to', 3130, 10), ('think', 3140, 20), ('about', 3160, 4), ('<eps>', 3164, 1), ('how', 3165, 18), ('that', 3183, 11), ('is', 3194, 2), ('<eps>', 3196, 3), ('going', 3199, 15), ('to', 3214, 20), ('<eps>', 3234, 77), ('hang', 3311, 40), ('<eps>', 3351, 7), ('right', 3358, 18), ('about', 3376, 30), ('there', 3406, 32), ('<eps>', 3438, 852), ('okay', 4290, 50), ('<eps>', 4340, 1899), ('okay', 6239, 53), ('<eps>', 6292, 579), ('and', 6871, 3), ('it', 6874, 10), ('needs', 6884, 37), ('<eps>', 6921, 46), ('another', 6967, 32), ('wire', 6999, 44), ('on', 7043, 20), ('it', 7063, 11), ('<eps>', 7074, 38), ('and', 7112, 10), ('we', 7122, 9), ('need', 7131, 17), ('another', 7148, 36), ('little', 7184, 25), ('wire', 7209, 52), ('<eps>', 7261, 285), ('to', 7546, 2), ('put', 7548, 26), ('<eps>', 7574, 1), ('up', 7575, 29), ('<eps>', 7604, 97), ('you', 7701, 2), ('can', 7703, 11), ('hang', 7714, 23), ('on', 7737, 11), ('your', 7748, 11), ('wall', 7759, 45), ('<eps>', 7804, 59), ('make', 7863, 3), ('a', 7866, 2), ('nice', 7868, 29), ('little', 7897, 18), ('circle', 7915, 49), ('<eps>', 7964, 94), ('inside', 8058, 55), ('my', 8113, 14), ('screw', 8127, 38), ('eye', 8165, 35), ('<eps>', 8200, 1399), ('okay', 9599, 34), ('<eps>', 9633, 89), ('now', 9722, 15), ('it', 9737, 2), ('is', 9739, 10), ('ready', 9749, 20), ('to', 9769, 16), ('<eps>', 9785, 5), ('be', 9790, 18), ('hung', 9808, 42), ('<eps>', 9850, 94), ('now', 9944, 15), ('it', 9959, 2), ('is', 9961, 10), ('ready', 9971, 21), ('to', 9992, 16), ('be', 10008, 18), ('hung', 10026, 42), ('<eps>', 10068, 45)]\n"
     ]
    }
   ],
   "source": [
    "# Ensure that you have run alignment_dependencies/path.sh in order to add Kaldi to the PATH\n",
    "\n",
    "\n",
    "#HACKY FIX IMPLEMENTED \n",
    "#IN PyKaldi API, if word not found in symbol table (out of vocabulary) it is set to <unk> or index 16. \n",
    "# The effect of this upon results needs to be discussed\n",
    "aspire_alignment();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAlignmentDeps(table):\n",
    "    tranlist = table['tran'].tolist()\n",
    "    idlist = table['id'].tolist()\n",
    "#generate spk2utt \n",
    "    with open(\"spk2utt\", 'w') as f:\n",
    "        for id in idlist:\n",
    "            print(f\"{id} {id}\", file=f)\n",
    "#generate text \n",
    "# BE SURE TO RENAME 'test' to 'text' !!\n",
    "    with open(\"test\", 'w') as f:\n",
    "        for index, id in enumerate(idlist):\n",
    "            tran = tranlist[index]\n",
    "            print(f\"{id} {tran}\", file=f)\n",
    "#generate wav.scp \n",
    "    with open(\"wav.scp\", 'w') as f:\n",
    "        for id in idlist:\n",
    "            print(f\"{id}  ../../speech_audios/{id}.wav\", file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generateAlignmentDeps(exploretable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
