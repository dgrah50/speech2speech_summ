{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech-to-Speech Abstractive Summarisation\n",
    "\n",
    "In this project we are Using How2 Dataset [link](https://srvk.github.io/how2-dataset/) which is a collection of instructional YouTube videos with English subtitles IDs and human-made summaries. This project is concerned with the transformation of audio to audio and as such, the audio has been ripped from the videos.\n",
    "\n",
    "* Task 1a) Construct databases of video transcriptions and human made descriptions\n",
    "* Task 1b) Download audios of 400 videos\n",
    "* Task 1c) Align transcriptions to the audios \n",
    "* Task 1d) Sequence Labelling and Feature Significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1a) Construct databases of video transcriptions and human made descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dayangraham/opt/anaconda3/envs/FYPenv/lib/python3.7/site-packages/ipykernel_launcher.py:11: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Load the test dataset into a pandas data frame\n",
    "import pandas as pd\n",
    "# Load the descriptions into a pandas data frame\n",
    "desctable = pd.read_csv('speech_data/text/sum_cv/desc.tok.txt', header=None, skipinitialspace=True, names=[\"a\"])\n",
    "desctable.head()\n",
    "filename = 'speech_data/text/sum_cv/tran.tok.txt'\n",
    "with open(filename, 'r') as f:\n",
    "    data = f.read().replace('\\n','%%%')\n",
    "    \n",
    "# Load the transcriptions into into a pandas data frame \n",
    "trantable = pd.read_csv(pd.compat.StringIO(data), sep=\"%%%\", header=None)\n",
    "trantable = trantable.T\n",
    "trantable.drop(trantable.tail(1).index,inplace=True)\n",
    "trantable.columns=['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>desc</th>\n",
       "      <th>tran</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-xd1aAlPXqs</td>\n",
       "      <td>learn the sivananda yoga single right leg rais...</td>\n",
       "      <td>after you 've done at least six to twelve roun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KtMjOT6fDrw</td>\n",
       "      <td>learn how to apply hanger hooks for your woodc...</td>\n",
       "      <td>on behalf of expert village , my name is husai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ehbFyYlcEhc</td>\n",
       "      <td>learn about how hand washing can help prevent ...</td>\n",
       "      <td>hi ! this is david jackel on behalf of expert ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lcw8f2od6z8</td>\n",
       "      <td>how to julienne cucumbers to make kimchi for k...</td>\n",
       "      <td>the other way we can do cucumbers which is als...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G-VRHmkiqtc</td>\n",
       "      <td>in order to put photographic emulsion on water...</td>\n",
       "      <td>my name is anthony maddaloni and i 'm going to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               desc  \\\n",
       "0  -xd1aAlPXqs  learn the sivananda yoga single right leg rais...   \n",
       "1  KtMjOT6fDrw  learn how to apply hanger hooks for your woodc...   \n",
       "2  ehbFyYlcEhc  learn about how hand washing can help prevent ...   \n",
       "3  lcw8f2od6z8  how to julienne cucumbers to make kimchi for k...   \n",
       "4  G-VRHmkiqtc  in order to put photographic emulsion on water...   \n",
       "\n",
       "                                                tran  \n",
       "0  after you 've done at least six to twelve roun...  \n",
       "1  on behalf of expert village , my name is husai...  \n",
       "2  hi ! this is david jackel on behalf of expert ...  \n",
       "3  the other way we can do cucumbers which is als...  \n",
       "4  my name is anthony maddaloni and i 'm going to...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split id and description\n",
    "desctable['id'] = desctable.apply(lambda row: str(row.a).split(\" \")[0], axis = 1) \n",
    "desctable['desc'] = desctable.apply(lambda row: ' '.join(str(row.a).split(\" \")[1:]), axis = 1) \n",
    "desctable.drop('a',1,inplace=True)\n",
    "# Split id and transcription\n",
    "trantable['id'] = trantable.apply(lambda row: row.a.split(\" \")[0], axis = 1) \n",
    "trantable['tran'] = trantable.apply(lambda row: ' '.join(row.a.split(\" \")[1:]), axis = 1) \n",
    "trantable.drop('a',1,inplace=True)\n",
    "\n",
    "# Join tables on ID to create a single table \n",
    "conctable = pd.merge(desctable,trantable,on=\"id\")\n",
    "conctable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1b) Download audios of 400 videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install dependencies to get audio from YouTube\n",
    "# !pip -q install wget youtube-dl wget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loop over the 400 YouTube videos\n",
    "# # Save each video's audio as 8000Hz wav\n",
    "# for YOUTUBE_ID in shortlist:\n",
    "#     !youtube-dl --extract-audio --audio-format wav --quiet --output \"{YOUTUBE_ID}_FULL.%(ext)s\" https://www.youtube.com/watch\\?v\\={YOUTUBE_ID}\n",
    "#     !ffmpeg -loglevel panic -y -i {YOUTUBE_ID}_FULL.wav -acodec pcm_s16le -ac 1 -ar 8000 {YOUTUBE_ID}.wav\n",
    "#     !rm {YOUTUBE_ID}_FULL.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Take the first 400 YouTube video IDs\n",
    "# youtube_ids = conctable['id'].tolist()\n",
    "# shortlist = youtube_ids[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploretable = conctable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploretable.loc[:,'intersection'] = exploretable.apply(lambda row: [value for value in row.desc.split(\" \") if value in row.tran.split(\" \")] , axis=1)\n",
    "exploretable.loc[:,'descnottran'] = exploretable.apply(lambda row: [value for value in row.desc.split(\" \") if value not in row.tran.split(\" \")] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROUGE statistics for the video descriptions and the video transcriptions\n",
    "from rouge import Rouge \n",
    "rouge = Rouge()\n",
    "exploretable['rouge1-f'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-1']['f'], axis=1)\n",
    "exploretable['rouge1-r'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-1']['r'], axis=1)\n",
    "exploretable['rouge1-p'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-1']['p'], axis=1)\n",
    "exploretable['rouge2-f'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-2']['f'], axis=1)\n",
    "exploretable['rouge2-r'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-2']['r'], axis=1)\n",
    "exploretable['rouge2-p'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-2']['p'], axis=1)\n",
    "exploretable['rougel-f'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-l']['f'], axis=1)\n",
    "exploretable['rougel-r'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-l']['r'], axis=1)\n",
    "exploretable['rougel-p'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-l']['p'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join\n",
    "exploretable['downloaded'] = exploretable.apply(lambda row: os.path.isfile(f'./speech_audios/{row.id}.wav'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "dt_string = datetime.now().strftime(\"%d%m%Y\")\n",
    "exploretable.to_pickle(f'./exploretable{dt_string}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1c) Align transcriptions to the audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alignment of transcription to audio\n",
    "\n",
    "# Define imports for Kaldi Alignment\n",
    "from kaldi.alignment import NnetAligner\n",
    "from kaldi.fstext import SymbolTable\n",
    "from kaldi.lat.align import WordBoundaryInfoNewOpts, WordBoundaryInfo\n",
    "from kaldi.nnet3 import NnetSimpleComputationOptions\n",
    "from kaldi.util.table import SequentialMatrixReader\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspire_alignment():\n",
    "    # Construct aligner\n",
    "    decodable_opts = NnetSimpleComputationOptions()\n",
    "    decodable_opts.acoustic_scale = 1.0\n",
    "    decodable_opts.frames_per_chunk = 150\n",
    "    aligner = NnetAligner.from_files(\n",
    "        \"exp/tdnn_7b_chain_online/final.mdl\",\n",
    "        \"exp/tdnn_7b_chain_online/tree\",\n",
    "        \"data/lang/L.fst\",\n",
    "        \"data/lang/words.txt\",\n",
    "        \"data/lang/phones/disambig.int\",\n",
    "        decodable_opts=decodable_opts)\n",
    "    phones = SymbolTable.read_text(\"data/lang/phones.txt\")\n",
    "    wb_info = WordBoundaryInfo.from_file(WordBoundaryInfoNewOpts(),\n",
    "                                         \"data/lang/phones/word_boundary.int\")\n",
    "\n",
    "    # Define feature pipelines as Kaldi rspecifiers\n",
    "    feats_rspec = (\n",
    "        \"ark:compute-mfcc-feats --config=conf/mfcc_hires.conf scp:data/test/wav.scp ark:- |\"\n",
    "    )\n",
    "    ivectors_rspec = (\n",
    "        \"ark:compute-mfcc-feats --config=conf/mfcc_hires.conf scp:data/test/wav.scp ark:- |\"\n",
    "        \"ivector-extract-online2 --config=conf/ivector_extractor.conf ark:data/test/spk2utt ark:- ark:- |\"\n",
    "    )\n",
    "\n",
    "    alignments=[]\n",
    "    # Align wav files\n",
    "    with SequentialMatrixReader(feats_rspec) as f, \\\n",
    "         SequentialMatrixReader(ivectors_rspec) as i, \\\n",
    "         open(\"data/test/text\",\"r\") as t:\n",
    "        for (fkey, feats), (ikey, ivectors), line in zip(f, i, t):\n",
    "            tkey, text = line.strip().split(None, 1)\n",
    "            text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "            assert(fkey == ikey == tkey)\n",
    "            out = aligner.align((feats, ivectors), text)\n",
    "            word_alignment = aligner.to_word_alignment(out[\"best_path\"], wb_info)\n",
    "#             print(tkey)\n",
    "            with open(f'alignments/{tkey}.txt', 'w') as f:\n",
    "                print(f\"{word_alignment}\", file=f)\n",
    "#             alignments.append(word_alignment)\n",
    "#             print(f\"The Input Text: {text}\")\n",
    "#             print(f\"The word alignment: {word_alignment}\")\n",
    "#     return alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File structure within the /data folder is as follows :\n",
    "-    /lang\n",
    "-    /test\n",
    "-        spk2utt - maps speakers to utterances? just repeat double unique id eg utt1 utt1\n",
    "-        text - transcription for each utterance on each line \n",
    "-        utt1.wav\n",
    "-        wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAlignmentDeps(table):\n",
    "    downloadtable = table.query('downloaded==True')\n",
    "    tranlist = downloadtable['tran'].tolist()\n",
    "    idlist = downloadtable['id'].tolist()\n",
    "#generate spk2utt \n",
    "    with open(\"data/test/spk2utt\", 'w') as f:\n",
    "        for id in idlist:\n",
    "            print(f\"{id} {id}\", file=f)\n",
    "#generate text \n",
    "    with open(\"data/test/text\", 'w') as f:\n",
    "        for index, id in enumerate(idlist):\n",
    "            tran = tranlist[index]\n",
    "            print(f\"{id} {tran}\", file=f)\n",
    "#generate wav.scp \n",
    "    with open(\"data/test/wav.scp\", 'w') as f:\n",
    "        for id in idlist:\n",
    "            print(f\"{id} speech_audios/{id}.wav\", file=f)\n",
    "\n",
    "generateAlignmentDeps(exploretable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that you have run alignment_dependencies/path.sh in order to add Kaldi to the PATH\n",
    "\n",
    "#HACKY FIX IMPLEMENTED \n",
    "#IN PyKaldi API, if word not found in symbol table (out of vocabulary) it is set to <unk> or index 16. \n",
    "# The effect of this upon results needs to be discussed\n",
    "aspire_alignment();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1d) Sequence Labelling and Feature Significance\n",
    "\n",
    "WAV file -> N-dimension feature vector\n",
    "*    The WAV file is analysed in 100ms frames\n",
    "*    For each 100ms frame a feature vector is generated containing the following information:\n",
    "*    The min, max, median, mean and range of the pitch (based on 10ms subframes)\n",
    "*    The min, max, median, mean and range of the energy (based on 10ms subframes)\n",
    "*    Mel Cepstral Coefficients + 1st and 2nd derivatives\n",
    "\n",
    "Frame * 100\n",
    "Utterance Length stays the same\n",
    "Alignment * 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "def playback(play_original, word_spacing,buffer,ID):\n",
    "    originalutterance = AudioSegment.from_wav(f'./speech_audios/{ID}.wav')\n",
    "    silence = AudioSegment.silent(duration=word_spacing)\n",
    "    if play_original:\n",
    "        play(originalutterance)\n",
    "    for word in word_alignment:\n",
    "        if (word[0] != '<eps>'):\n",
    "            start_time = word[1]*10-buffer\n",
    "            end_time = start_time + word[2]*10+buffer\n",
    "            print(word[0])\n",
    "            snippet = originalutterance[start_time:end_time]\n",
    "            padded_snippet = silence.append(snippet.append(silence, crossfade=word_spacing/2),crossfade=word_spacing/2)\n",
    "            play(padded_snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "matfiles = [file for file in listdir(\"./acoustic_feats_170520/\") if file.endswith('.mat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from pydub import AudioSegment\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('en')\n",
    "\n",
    "FEATUREPATH = \"./acoustic_feats_170520/\"\n",
    "AUDIOPATH = \"./speech_audios/\"\n",
    "ALIGNMENTPATH = \"alignments/\"\n",
    "\n",
    "positives=[]\n",
    "negatives=[]\n",
    "for matfile in matfiles[:20]:\n",
    "    try:\n",
    "        feats = scipy.io.loadmat(FEATUREPATH+matfile)['ret']\n",
    "        chosenid = matfile.replace(\".mat\",\"\")\n",
    "        audiofile = AudioSegment.from_wav(f'{AUDIOPATH}{chosenid}.wav')\n",
    "        alignment =  eval(open(f'{ALIGNMENTPATH}{chosenid}.txt', \"r\").read())\n",
    "\n",
    "        row = exploretable.query(f'id==\"{chosenid}\"')\n",
    "        description = set(row['desc'].values[0].split(\" \"))\n",
    "        transcription = set(row['tran'].values[0].split(\" \"))\n",
    "        intersection = description&transcription\n",
    "\n",
    "        importantwords = list(filter(lambda x: x[0] in intersection and x[0] not in stop_words, alignment))\n",
    "\n",
    "        impidx = []\n",
    "        for imp in importantwords:\n",
    "            start = (imp[1]- (imp[1]%10))//10 \n",
    "            gap =  round((imp[2]/10- (imp[2]%1)))\n",
    "            end = start + gap\n",
    "            idx = list(range(start,end))\n",
    "            impidx.extend(idx)\n",
    "        positiveframes=feats[impidx]\n",
    "        negativeframes=np.delete(feats, impidx,axis=0)\n",
    "        positives.extend(positiveframes)\n",
    "        negatives.extend(negativeframes)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "positives =  np.asarray(positives)\n",
    "negatives =  np.asarray(negatives)\n",
    "data = np.concatenate((positives, negatives))\n",
    "data = preprocessing.scale(data)\n",
    "labels = [1]*len(positives) + [0]*len(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of y_test is 4796\n",
      "The 1s in  Y_pred are (array([0, 1]), array([4738,   58]))\n",
      "The 1s in  y_test are (array([0, 1]), array([4669,  127]))\n",
      "(0.6349434506047946, 0.5625384720463166, 0.5838659537607129, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=123)\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "#Create a svm Classifier\n",
    "clf = svm.SVC(class_weight={1: 10}) \n",
    "\n",
    "#Train the model using the training sets\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "clf.score(X_test,y_test)\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "print(f\"The length of y_test is {len(y_test)}\")\n",
    "print(f\"The 1s in  Y_pred are {np.unique(Y_pred, return_counts=True)}\")\n",
    "print(f\"The 1s in  y_test are {np.unique(y_test, return_counts=True)}\")\n",
    "print(precision_recall_fscore_support(y_test, Y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of y_test is 4796\n",
      "The 1s in  Y_pred are (array([0, 1]), array([4509,  287]))\n",
      "The 1s in  y_test are (array([0, 1]), array([4669,  127]))\n",
      "(0.5174188981695919, 0.538015019486882, 0.5203611240068932, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logi = LogisticRegression(random_state=0,class_weight={1: 16}).fit(X_train, y_train)\n",
    "res = logi.predict(X_test)\n",
    "print(f\"The length of y_test is {len(y_test)}\")\n",
    "print(f\"The 1s in  Y_pred are {np.unique(res, return_counts=True)}\")\n",
    "print(f\"The 1s in  y_test are {np.unique(y_test, return_counts=True)}\")\n",
    "print(precision_recall_fscore_support(y_test, res, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of y_test is 4796\n",
      "The 1s in  Y_pred are (array([0, 1]), array([4731,   65]))\n",
      "The 1s in  y_test are (array([0, 1]), array([4669,  127]))\n",
      "(0.6035477944165325, 0.5537006524859055, 0.5695079787234043, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf=RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train,y_train)\n",
    "rf_pred=clf.predict(X_test)\n",
    "print(f\"The length of y_test is {len(y_test)}\")\n",
    "print(f\"The 1s in  Y_pred are {np.unique(rf_pred, return_counts=True)}\")\n",
    "print(f\"The 1s in  y_test are {np.unique(y_test, return_counts=True)}\")\n",
    "print(precision_recall_fscore_support(y_test, rf_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.Series(rf.feature_importances_).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    0.030916\n",
       "16    0.029299\n",
       "12    0.028069\n",
       "13    0.027207\n",
       "25    0.025781\n",
       "41    0.025079\n",
       "34    0.025000\n",
       "18    0.024783\n",
       "32    0.024633\n",
       "9     0.024064\n",
       "33    0.023920\n",
       "8     0.023485\n",
       "6     0.023427\n",
       "5     0.023427\n",
       "40    0.023235\n",
       "36    0.022746\n",
       "31    0.022599\n",
       "42    0.022571\n",
       "15    0.022464\n",
       "11    0.022453\n",
       "30    0.022394\n",
       "27    0.022161\n",
       "19    0.021830\n",
       "21    0.021767\n",
       "29    0.021633\n",
       "43    0.021362\n",
       "44    0.021317\n",
       "24    0.021177\n",
       "38    0.021062\n",
       "35    0.020888\n",
       "20    0.020804\n",
       "37    0.020755\n",
       "2     0.020683\n",
       "7     0.020278\n",
       "23    0.020206\n",
       "4     0.020096\n",
       "14    0.020036\n",
       "39    0.019651\n",
       "17    0.019201\n",
       "3     0.018829\n",
       "28    0.018774\n",
       "22    0.018747\n",
       "1     0.018335\n",
       "26    0.018181\n",
       "0     0.014674\n",
       "dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of y_test is 4796\n",
      "The 1s in  Y_pred are (array([0, 1]), array([4731,   65]))\n",
      "The 1s in  y_test are (array([0, 1]), array([4669,  127]))\n",
      "(0.6035477944165325, 0.5537006524859055, 0.5695079787234043, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy=\"constant\",constant=0)\n",
    "dummy_clf.fit(X_train,y_train)\n",
    "dummy_clf_pred=clf.predict(X_test)\n",
    "print(f\"The length of y_test is {len(y_test)}\")\n",
    "print(f\"The 1s in  Y_pred are {np.unique(dummy_clf_pred, return_counts=True)}\")\n",
    "print(f\"The 1s in  y_test are {np.unique(y_test, return_counts=True)}\")\n",
    "print(precision_recall_fscore_support(y_test, dummy_clf_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Confusion matrix', None)\n",
      "[[4628   41]\n",
      " [ 110   17]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "titles_options = [(\"Confusion matrix\", None)]\n",
    "for title in titles_options:\n",
    "    disp = plot_confusion_matrix(clf, X_test, y_test,\n",
    "                                 cmap=plt.cm.Blues)\n",
    "    disp.ax_.set_title(title)\n",
    "\n",
    "    print(title)\n",
    "    print(disp.confusion_matrix)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
