{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speech-to-Speech Abstractive Summarisation\n",
    "\n",
    "In this project we are Using How2 Dataset [link](https://srvk.github.io/how2-dataset/) which is a collection of instructional YouTube videos with English subtitles IDs and human-made summaries. This project is concerned with the transformation of audio to audio and as such, the audio has been ripped from the videos.\n",
    "\n",
    "* Task A) Construct databases of video transcriptions and human made descriptions\n",
    "* Task B) Download audios of 400 videos\n",
    "* Task C) Align transcriptions to the audios \n",
    "* Task D) Sequence Labelling and Feature Significance\n",
    "* Task E) Audio Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset into a pandas data frame\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import spacy\n",
    "import scipy.io\n",
    "import math\n",
    "import pickle \n",
    "import Levenshtein\n",
    "from sklearn import preprocessing\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "from gensim.summarization.summarizer import summarize as extractive_sum\n",
    "from rouge import Rouge \n",
    "from allennlp.data.tokenizers import Token, Tokenizer, SpacyTokenizer\n",
    "from statistics import stdev \n",
    "\n",
    "rouge = Rouge()\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task A) Construct databases of video transcriptions and human made descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load the descriptions into a pandas data frame\n",
    "desctable = pd.read_csv('speech_data/text/sum_cv/desc.tok.txt', header=None, skipinitialspace=True, names=[\"a\"])\n",
    "desctable.head()\n",
    "filename = 'speech_data/text/sum_cv/tran.tok.txt'\n",
    "with open(filename, 'r') as f:\n",
    "    data = f.read().replace('\\n','%%%')\n",
    "    pick\n",
    "# Load the transcriptions into into a pandas data frame \n",
    "trantable = pd.read_csv(pd.compat.StringIO(data), sep=\"%%%\", header=None)\n",
    "trantable = trantable.T\n",
    "trantable.drop(trantable.tail(1).index,inplace=True)\n",
    "trantable.columns=['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split id and description\n",
    "desctable['id'] = desctable.apply(lambda row: str(row.a).split(\" \")[0], axis = 1) \n",
    "desctable['desc'] = desctable.apply(lambda row: ' '.join(str(row.a).split(\" \")[1:]), axis = 1) \n",
    "desctable.drop('a',1,inplace=True)\n",
    "# Split id and transcription\n",
    "trantable['id'] = trantable.apply(lambda row: row.a.split(\" \")[0], axis = 1) \n",
    "trantable['tran'] = trantable.apply(lambda row: ' '.join(row.a.split(\" \")[1:]), axis = 1) \n",
    "trantable.drop('a',1,inplace=True)\n",
    "\n",
    "# Join tables on ID to create a single table \n",
    "conctable = pd.merge(desctable,trantable,on=\"id\")\n",
    "conctable.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task B) Download audios of 400 videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Install dependencies to get audio from YouTube\n",
    "# !pip -q install wget youtube-dl wget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Loop over the 400 YouTube videos\n",
    "# # Save each video's audio as 8000Hz wav\n",
    "# for YOUTUBE_ID in shortlist:\n",
    "#     !youtube-dl --extract-audio --audio-format wav --quiet --output \"{YOUTUBE_ID}_FULL.%(ext)s\" https://www.youtube.com/watch\\?v\\={YOUTUBE_ID}\n",
    "#     !ffmpeg -loglevel panic -y -i {YOUTUBE_ID}_FULL.wav -acodec pcm_s16le -ac 1 -ar 8000 {YOUTUBE_ID}.wav\n",
    "#     !rm {YOUTUBE_ID}_FULL.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Take the first 400 YouTube video IDs\n",
    "# youtube_ids = conctable['id'].tolist()\n",
    "# shortlist = youtube_ids[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exploretable = conctable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exploretable.loc[:,'intersection'] = exploretable.apply(lambda row: [value for value in row.desc.split(\" \") if value in row.tran.split(\" \")] , axis=1)\n",
    "exploretable.loc[:,'descnottran'] = exploretable.apply(lambda row: [value for value in row.desc.split(\" \") if value not in row.tran.split(\" \")] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calculate ROUGE statistics for the video descriptions and the video transcriptions\n",
    "exploretable['rouge1-f'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-1']['f'], axis=1)\n",
    "exploretable['rouge1-r'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-1']['r'], axis=1)\n",
    "exploretable['rouge1-p'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-1']['p'], axis=1)\n",
    "exploretable['rouge2-f'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-2']['f'], axis=1)\n",
    "exploretable['rouge2-r'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-2']['r'], axis=1)\n",
    "exploretable['rouge2-p'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-2']['p'], axis=1)\n",
    "exploretable['rougel-f'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-l']['f'], axis=1)\n",
    "exploretable['rougel-r'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-l']['r'], axis=1)\n",
    "exploretable['rougel-p'] = exploretable.apply(lambda row:  rouge.get_scores(row.desc, row.tran)[0]['rouge-l']['p'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join\n",
    "exploretable['downloaded'] = exploretable.apply(lambda row: os.path.isfile(f'./speech_audios/{row.id}.wav'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "dt_string = datetime.now().strftime(\"%d%m%Y\")\n",
    "exploretable.to_pickle(f'./exploretable{dt_string}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task C) Align transcriptions to the audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Alignment of transcription to audio\n",
    "# Define imports for Kaldi Alignment\n",
    "from kaldi.alignment import NnetAligner\n",
    "from kaldi.fstext import SymbolTable\n",
    "from kaldi.lat.align import WordBoundaryInfoNewOpts, WordBoundaryInfo\n",
    "from kaldi.nnet3 import NnetSimpleComputationOptions\n",
    "from kaldi.util.table import SequentialMatrixReader\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def aspire_alignment():\n",
    "    # Construct aligner\n",
    "    decodable_opts = NnetSimpleComputationOptions()\n",
    "    decodable_opts.acoustic_scale = 1.0\n",
    "    decodable_opts.frames_per_chunk = 150\n",
    "    aligner = NnetAligner.from_files(\n",
    "        \"exp/tdnn_7b_chain_online/final.mdl\",\n",
    "        \"exp/tdnn_7b_chain_online/tree\",\n",
    "        \"data/lang/L.fst\",\n",
    "        \"data/lang/words.txt\",\n",
    "        \"data/lang/phones/disambig.int\",\n",
    "        decodable_opts=decodable_opts)\n",
    "    phones = SymbolTable.read_text(\"data/lang/phones.txt\")\n",
    "    wb_info = WordBoundaryInfo.from_file(WordBoundaryInfoNewOpts(),\n",
    "                                         \"data/lang/phones/word_boundary.int\")\n",
    "\n",
    "    # Define feature pipelines as Kaldi rspecifiers\n",
    "    feats_rspec = (\n",
    "        \"ark:compute-mfcc-feats --config=conf/mfcc_hires.conf scp:data/test/wav.scp ark:- |\"\n",
    "    )\n",
    "    ivectors_rspec = (\n",
    "        \"ark:compute-mfcc-feats --config=conf/mfcc_hires.conf scp:data/test/wav.scp ark:- |\"\n",
    "        \"ivector-extract-online2 --config=conf/ivector_extractor.conf ark:data/test/spk2utt ark:- ark:- |\"\n",
    "    )\n",
    "\n",
    "    alignments=[]\n",
    "    # Align wav files\n",
    "    with SequentialMatrixReader(feats_rspec) as f, \\\n",
    "         SequentialMatrixReader(ivectors_rspec) as i, \\\n",
    "         open(\"data/test/text\",\"r\") as t:\n",
    "        for (fkey, feats), (ikey, ivectors), line in zip(f, i, t):\n",
    "            tkey, text = line.strip().split(None, 1)\n",
    "            text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "            assert(fkey == ikey == tkey)\n",
    "            out = aligner.align((feats, ivectors), text)\n",
    "            word_alignment = aligner.to_word_alignment(out[\"best_path\"], wb_info)\n",
    "\n",
    "            with open(f'alignments/{tkey}.txt', 'w') as f:\n",
    "                print(f\"{word_alignment}\", file=f)\n",
    "    return alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### File structure within the /data folder is as follows :\n",
    "-    /lang\n",
    "-    /test\n",
    "-        spk2utt - maps speakers to utterances? just repeat double unique id eg utt1 utt1\n",
    "-        text - transcription for each utterance on each line \n",
    "-        utt1.wav\n",
    "-        wav.scp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def generateAlignmentDeps(table):\n",
    "    downloadtable = table.query('downloaded==True')\n",
    "    tranlist = downloadtable['tran'].tolist()\n",
    "    idlist = downloadtable['id'].tolist()\n",
    "#generate spk2utt \n",
    "    with open(\"data/test/spk2utt\", 'w') as f:\n",
    "        for id in idlist:\n",
    "            print(f\"{id} {id}\", file=f)\n",
    "#generate text \n",
    "    with open(\"data/test/text\", 'w') as f:\n",
    "        for index, id in enumerate(idlist):\n",
    "            tran = tranlist[index]\n",
    "            print(f\"{id} {tran}\", file=f)\n",
    "#generate wav.scp \n",
    "    with open(\"data/test/wav.scp\", 'w') as f:\n",
    "        for id in idlist:\n",
    "            print(f\"{id} speech_audios/{id}.wav\", file=f)\n",
    "\n",
    "generateAlignmentDeps(exploretable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Ensure that you have run alignment_dependencies/path.sh in order to add Kaldi to the PATH\n",
    "\n",
    "#HACKY FIX IMPLEMENTED \n",
    "#IN PyKaldi API, if word not found in symbol table (out of vocabulary) it is set to <unk> or index 16. \n",
    "# The effect of this upon results needs to be discussed\n",
    "aspire_alignment();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task D) Sequence Labelling and Feature Significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "WAV file -> 45-dimension feature vector\n",
    "*    The WAV file is analysed in 100ms frames\n",
    "*    For each 100ms frame a feature vector is generated containing the following information:\n",
    "*    The min, max, median, mean and range of the pitch (based on 10ms subframes)\n",
    "*    The min, max, median, mean and range of the energy (based on 10ms subframes)\n",
    "*    Mel Cepstral Coefficients + 1st and 2nd derivatives\n",
    "\n",
    "Frame * 100\n",
    "Utterance Length stays the same\n",
    "Alignment * 10\n",
    "\n",
    "| Index |                 Feature                |\n",
    "|:-----:|:--------------------------------------:|\n",
    "|   0   | VAD                                    |\n",
    "|   1   | Pitch - Low                            |\n",
    "|   2   | Pitch - High                           |\n",
    "|   3   | Pitch - Median                         |\n",
    "|   4   | Pitch - Mean                           |\n",
    "|   5   | Pitch - Range                          |\n",
    "|  6-17 | Cepstral Coefficients 1-12             |\n",
    "|   18  | Energy                                 |\n",
    "| 19-31 | 1st Diff of Cepstral Coefficients 1-12 |\n",
    "|   32  | 1st Diff of Energy                     |\n",
    "| 33-44 | 2nd Diff of Cepstral Coefficients 1-12 |\n",
    "|   45  | 2nd Diff of Energy                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "matfiles = [file for file in listdir(\"./acoustic_feats_170520/\") if file.endswith('.mat')]\n",
    "exploretable = pd.read_pickle(\"./exploretable16052020.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     13
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('en')\n",
    "\n",
    "\n",
    "selected_indexes = []\n",
    "if bool(input(\"Include Voice Activity Detection? Y/n?\").lower()!='n'):\n",
    "    selected_indexes.append(0)\n",
    "if bool(input(\"Include Pitch Statistics? Y/n?\").lower()!='n'):\n",
    "    selected_indexes.extend(list(range(1,6)))\n",
    "if bool(input(\"Include mel? Y/n?\").lower()!='n'):\n",
    "    selected_indexes.extend(list(range(6,20)))\n",
    "if bool(input(\"Include 1st diff of mel? Y/n?\").lower()!='n'):\n",
    "    selected_indexes.extend(list(range(20,34)))\n",
    "if  bool(input(\"Include 2nd diff of mel? Y/n?\").lower()!='n'):\n",
    "    selected_indexes.extend(list(range(34,45)))\n",
    "\n",
    "print(selected_indexes)\n",
    "    \n",
    "FEATUREPATH = \"./acoustic_feats_170520/\"\n",
    "AUDIOPATH = \"./speech_audios/\"\n",
    "ALIGNMENTPATH = \"alignments/\"\n",
    "\n",
    "positives=[]\n",
    "negatives=[]\n",
    "for matfile in matfiles[:30]:\n",
    "    try:\n",
    "        feats = scipy.io.loadmat(FEATUREPATH+matfile)['ret']\n",
    "        feats = feats[:, selected_indexes]\n",
    "        chosenid = matfile.replace(\".mat\",\"\")\n",
    "        audiofile = AudioSegment.from_wav(f'{AUDIOPATH}{chosenid}.wav')\n",
    "        alignment =  eval(open(f'{ALIGNMENTPATH}{chosenid}.txt', \"r\").read())\n",
    "        row = exploretable.query(f'id==\"{chosenid}\"')\n",
    "        description = set(row['desc'].values[0].split(\" \"))\n",
    "        transcription = set(row['tran'].values[0].split(\" \"))\n",
    "        intersection = description&transcription\n",
    "\n",
    "        importantwords = list(filter(lambda x: x[0] in intersection and x[0] not in stop_words, alignment))\n",
    "\n",
    "        impidx = []\n",
    "        for imp in importantwords:\n",
    "#             print(imp)\n",
    "            start = math.ceil((imp[1])/10) \n",
    "            gap =  math.floor((imp[2]/10- (imp[2]%1)))\n",
    "            end = start + gap +1\n",
    "#             print (start,end)\n",
    "            idx = list(range(start,end))\n",
    "#             print(idx)\n",
    "            impidx.extend(idx)\n",
    "        positiveframes=feats[impidx]\n",
    "        negativeframes=np.delete(feats, impidx,axis=0)\n",
    "        positives.extend(positiveframes)\n",
    "        negatives.extend(negativeframes)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "positives =  np.asarray(positives)\n",
    "negatives =  np.asarray(negatives)\n",
    "data = np.concatenate((positives, negatives))\n",
    "data = preprocessing.scale(data)\n",
    "labels = [1]*len(positives) + [0]*len(negatives)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=123)\n",
    "print(\"Data loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task D-1) SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "#Create a svm regressor\n",
    "# clf = svm.NuSVR(C=25.0, nu=0.5, kernel='rbf', max_iter=-1, verbose=1) \n",
    "\n",
    "#Train the model using the training sets\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('best_svm.sav', 'rb') as pickle_file:\n",
    "    clf = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = clf.predict(X_test)\n",
    "def avg(lst):\n",
    "    return sum(lst)/len(lst)\n",
    "\n",
    "nonzeroind = np.nonzero(y_test)[0]\n",
    "real_ones = res[nonzeroind]\n",
    "print(avg(real_ones))\n",
    "zeroind =  [idx for idx, val in enumerate(y_test) if val == 0] \n",
    "real_zeros = res[zeroind]\n",
    "print(avg(real_zeros))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "fig = plt.figure()\n",
    "plt.hist(real_zeros,np.arange(0,1,0.01));\n",
    "fig.suptitle('Distribution of the predicted prominence score of the negative frames - SVM', fontsize=20)\n",
    "plt.xlabel('Prominence Score', fontsize=18)\n",
    "plt.ylabel('Number of Frames', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "fig = plt.figure()\n",
    "plt.hist(real_ones,np.arange(0,1,0.01));\n",
    "fig.suptitle('Distribution of the predicted prominence score of the positive frames - SVM', fontsize=20)\n",
    "plt.xlabel('Prominence Score', fontsize=18)\n",
    "plt.ylabel('Number of Frames', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = len(list(filter(lambda x : x>0.5, real_ones)))\n",
    "FP = len(list(filter(lambda x : x>0.5, real_zeros)))\n",
    "TN = len(list(filter(lambda x : x<0.5, real_zeros)))\n",
    "FN = len(list(filter(lambda x : x<0.5, real_ones)))\n",
    "\n",
    "precision = TP /(TP+FP)\n",
    "recall = TP / (TP+FN)\n",
    "F1 = 2*precision*recall/(precision+recall)\n",
    "print(precision,recall,F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task D-2) Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "clf = MLPRegressor(\n",
    "    verbose=True,\n",
    "    random_state=5,\n",
    "    activation='tanh',\n",
    "    solver='adam', \n",
    "    max_iter=500,\n",
    "    hidden_layer_sizes=(300,200,200)\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import logistic\n",
    "res = clf.predict(X_test)\n",
    "def avg(lst):\n",
    "    return sum(lst)/len(lst)\n",
    "\n",
    "nonzeroind = np.nonzero(y_test)[0]\n",
    "real_ones = res[nonzeroind]\n",
    "# real_ones = np.tanh(real_ones)\n",
    "print(avg(real_ones))\n",
    "zeroind =  [idx for idx, val in enumerate(y_test) if val == 0] \n",
    "real_zeros = res[zeroind]\n",
    "# real_zeros = np.tanh(real_zeros)\n",
    "print(avg(real_zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "fig = plt.figure()\n",
    "plt.hist(real_zeros,np.arange(0,1,0.01));\n",
    "fig.suptitle('Distribution of the predicted prominence score of the negative frames - NN', fontsize=20)\n",
    "plt.xlabel('Prominence Score', fontsize=18)\n",
    "plt.ylabel('Number of Frames', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "fig = plt.figure()\n",
    "plt.hist(real_ones,np.arange(0,1,0.01));\n",
    "fig.suptitle('Distribution of the predicted prominence score of the positive frames - NN', fontsize=20)\n",
    "plt.xlabel('Prominence Score', fontsize=18)\n",
    "plt.ylabel('Number of Frames', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = len(list(filter(lambda x : x>0.5, real_ones)))\n",
    "FP = len(list(filter(lambda x : x>0.5, real_zeros)))\n",
    "TN = len(list(filter(lambda x : x<0.5, real_zeros)))\n",
    "FN = len(list(filter(lambda x : x<0.5, real_ones)))\n",
    "\n",
    "precision = TP /(TP+FP)\n",
    "recall = TP / (TP+FN)\n",
    "F1 = 2*precision*recall/(precision+recall)\n",
    "print(precision,recall,F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task D-3) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf=RandomForestRegressor(max_depth=2, random_state=0)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = rf.predict(X_test)\n",
    "def avg(lst):\n",
    "    return sum(lst)/len(lst)\n",
    "\n",
    "nonzeroind = np.nonzero(y_test)[0]\n",
    "real_ones = res[nonzeroind]\n",
    "print(avg(real_ones))\n",
    "zeroind =  [idx for idx, val in enumerate(y_test) if val == 0] \n",
    "real_zeros = res[zeroind]\n",
    "print(avg(real_zeros))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(real_zeros,np.arange(0,1,0.01));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(real_ones,np.arange(0,1,0.01));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "featimp = pd.Series(rf.feature_importances_).T\n",
    "ax = featimp.plot(kind='bar', title =\"Acoustic Feature Importance\", figsize=(15, 10), fontsize=12)\n",
    "ax.set_xlabel(\"Feature Index\", fontsize=20)\n",
    "ax.set_ylabel(\"Feature importance\", fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task D-4) Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_regression = LogisticRegression(random_state=0,class_weight={1: 23}).fit(X_train, y_train)\n",
    "predicted_values = logistic_regression.predict(X_test)\n",
    "def avg(lst):\n",
    "    return sum(lst)/len(lst)\n",
    "\n",
    "nonzeroind = np.nonzero(y_test)[0]\n",
    "real_ones = predicted_values[nonzeroind]\n",
    "print(avg(real_ones))\n",
    "zeroind =  [idx for idx, val in enumerate(y_test) if val == 0] \n",
    "real_zeros = predicted_values[zeroind]\n",
    "print(avg(real_zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "fig = plt.figure()\n",
    "plt.hist(real_zeros,np.arange(0,1,0.01));\n",
    "fig.suptitle('Distribution of the predicted prominence score of the negative frames - Logistic', fontsize=20)\n",
    "plt.xlabel('Prominence Score', fontsize=18)\n",
    "plt.ylabel('Number of Frames', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "fig = plt.figure()\n",
    "plt.hist(real_zeros,np.arange(0,1,0.01));\n",
    "fig.suptitle('Distribution of the predicted prominence score of the positive frames - NN', fontsize=20)\n",
    "plt.xlabel('Prominence Score', fontsize=18)\n",
    "plt.ylabel('Number of Frames', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = len(list(filter(lambda x : x>0.5, real_ones)))\n",
    "FP = len(list(filter(lambda x : x>0.5, real_zeros)))\n",
    "TN = len(list(filter(lambda x : x<0.5, real_zeros)))\n",
    "FN = len(list(filter(lambda x : x<0.5, real_ones)))\n",
    "\n",
    "precision = TP /(TP+FP)\n",
    "recall = TP / (TP+FN)\n",
    "F1 = 2*precision*recall/(precision+recall)\n",
    "print(precision,recall,F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Task D-6) Final Score Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('best_svm.sav', 'rb') as pickle_file:\n",
    "    clf = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def acoustic_prominence_scorer(featureleng,alignment): \n",
    "\n",
    "    raw_scores = clf.predict(featureleng)\n",
    "    scored_sequence = {}\n",
    "    appearances = {}\n",
    "    for x in alignment :\n",
    "        if x[0] != '<eps>':\n",
    "            start = math.ceil((x[1])/10)-1\n",
    "            gap =  math.floor((x[2]/10- (x[2]%1)))+1\n",
    "            end= start+gap\n",
    "            relevant_scores = raw_scores[start:end]\n",
    "            mean_score = sum(relevant_scores)/len(relevant_scores)\n",
    "            if x[0] in appearances:\n",
    "                new_freq = appearances[x[0]]+1\n",
    "                appearances[x[0]] = new_freq\n",
    "                scored_sequence[x[0]] = ((new_freq-1) * appearances[x[0]] + mean_score) / new_freq\n",
    "            else:\n",
    "                appearances[x[0]] = 1\n",
    "                scored_sequence[x[0]] = mean_score\n",
    "    return scored_sequence\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "sigmoid_v = np.vectorize(sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ALIGNMENTPATH = \"alignments/\"\n",
    "FEATUREPATH = \"./acoustic_feats_170520/\"\n",
    "exploretable = pd.read_pickle(\"./exploretable16052020.pkl\")\n",
    "text = exploretable.iloc[4]['tran']\n",
    "textdesc = exploretable.iloc[4]['desc']\n",
    "chosenid = exploretable.iloc[4]['id']\n",
    "alignment =  eval(open(f'{ALIGNMENTPATH}{chosenid}.txt', \"r\").read())\n",
    "feats = scipy.io.loadmat(FEATUREPATH+chosenid)['ret']\n",
    "feats = preprocessing.scale(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data =  acoustic_prominence_scorer(feats,alignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task E) Audio Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  Task E1) Mode 1 - Extractive Summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ALIGNMENTPATH = \"alignments/\"\n",
    "exploretable = pd.read_pickle(\"./exploretable16052020.pkl\")\n",
    "text = exploretable.iloc[2]['tran']\n",
    "textdesc = exploretable.iloc[2]['desc']\n",
    "chosenid = exploretable.iloc[2]['id']\n",
    "alignment =  eval(open(f'{ALIGNMENTPATH}{chosenid}.txt', \"r\").read())\n",
    "summary = extractive_sum(text,word_count=40)\n",
    "# print(summary)\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def find_start_indexes(alignment,summary):\n",
    "    indexes = []\n",
    "    for idx, i in enumerate(alignment):\n",
    "        if (summary[0] == i[0] ):\n",
    "            indexes.append(idx)\n",
    "    return indexes\n",
    "\n",
    "def find_end_indexes(alignment,summary):\n",
    "    lastword = summary[-1]\n",
    "    if lastword in string.punctuation: \n",
    "        return find_end_indexes(alignment,summary[:-1])\n",
    "    indexes = [index for index, m in enumerate(alignment) if re.match(f\"\\('{lastword}', \\d+, \\d+\\)\", str(m))]\n",
    "\n",
    "    if (indexes != []):\n",
    "        return indexes\n",
    "    else:\n",
    "        return find_end_indexes(alignment,list(reversed(summary))[:-1])\n",
    "\n",
    "start_indexes = find_start_indexes(alignment,summary.split(\" \"))      \n",
    "end_indexes = find_end_indexes(alignment,summary.split(\" \"))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "editdistance = 99999\n",
    "for i in start_indexes:\n",
    "    for j in end_indexes:\n",
    "        candidate = alignment[i:j+1]\n",
    "        candidate = [x[0] for x in candidate if x[0] != '<eps>']\n",
    "        candidate = \" \".join(candidate)\n",
    "        candidatedistance = Levenshtein.distance(candidate,summary)\n",
    "        if ( candidatedistance < editdistance):\n",
    "            editdistance = candidatedistance\n",
    "            mini = i\n",
    "            minj = j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "audiostart = alignment[mini][1]*10\n",
    "audioend= (alignment[minj][1]+alignment[minj][2])*10\n",
    "originalutterance = AudioSegment.from_wav(f'./speech_audios/{chosenid}.wav')\n",
    "play(originalutterance[audiostart:audioend])\n",
    "print(audiostart)\n",
    "print(audioend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  Task E2) Mode 2 - Abstractive Summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "import pandas as pd\n",
    "# abstractive_sum = pipeline(task=\"summarization\")\n",
    "exploretable = pd.read_pickle(\"./exploretable16052020.pkl\")\n",
    "text = exploretable.iloc[0]['tran']\n",
    "# summary = abstractive_sum(\n",
    "#     text,\n",
    "#     max_length=80\n",
    "# )\n",
    "\n",
    "print(text)\n",
    "# print(\" \")\n",
    "# print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exploretable\n",
    "desc_list = exploretable['desc'].tolist()\n",
    "tran_list = exploretable['tran'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "tran_train, tran_val, desc_train, desc_val= train_test_split(\n",
    "    tran_list, desc_list, test_size=0.25, random_state=42)\n",
    "\n",
    "tran_dev, tran_test, desc_dev, desc_test= train_test_split(\n",
    "    tran_val, desc_val, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "desc_tran_train = list(zip(tran_train,desc_train))\n",
    "desc_tran_dev = list(zip(tran_dev,desc_dev))\n",
    "desc_tran_test = list(zip(tran_test,desc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "desc_tran_test[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f = open('train.tsv', 'w')\n",
    "for x in desc_tran_train:\n",
    "    f.write(x[0]+\"\\t\"+x[1]+\"\\n\")\n",
    "f.close()\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "####  Task E3) Mode 3 - Hybrid Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import nlpete.training.metrics\n",
    "import nlpete.data.dataset_readers\n",
    "from nlpete.models.copynet import CopyNet\n",
    "from allennlp.data.fields.text_field import TextFieldTensors\n",
    "from overrides import overrides\n",
    "from allennlp.models.archival import load_archive\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.data import DatasetReader\n",
    "from allennlp.common.util import JsonDict\n",
    "from allennlp.data import Instance\n",
    "from nlpete.data.dataset_readers import (\n",
    "    CopyNetDatasetReader,\n",
    ") \n",
    "from allennlp.predictors import Predictor\n",
    "import warnings\n",
    "class CopyNetPredictor(Predictor):\n",
    "    \"\"\"\n",
    "    Predictor for the CopyNet model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: Model, dataset_reader: DatasetReader) -> None:\n",
    "        super().__init__(model, dataset_reader)\n",
    "        warnings.warn(\n",
    "            \"The 'copynet' predictor has been deprecated in favor of \"\n",
    "            \"the 'seq2seq' predictor.\",\n",
    "            DeprecationWarning,\n",
    "        )\n",
    "\n",
    "    def predict(self, source: str,acoustic_data: str) -> JsonDict:\n",
    "        return self.predict_json({\"source_string\": source,\"acoustic_data\":acoustic_data})\n",
    "\n",
    "    @overrides\n",
    "    def _json_to_instance(self, json_dict: JsonDict) -> Instance:\n",
    "        source = json_dict[\"source_string\"]\n",
    "        acoustic_data = json_dict[\"acoustic_data\"]\n",
    "        return self._dataset_reader.text_to_instance(source,acoustic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exploretable = pd.read_pickle(\"./exploretable16052020.pkl\")\n",
    "# input_string = tran = exploretable.iloc[15]['tran']\n",
    "input_string = \"after you 've done at least six to twelve rounds of sun salutation in sivananda yoga we start on the main practice . we will begin with leg raises . it really helps open up the core , strengthen the core , and it 's just a wonderful way to start . so i 'm going to have lauren here lay down on her back . beautiful . now bring your arms down to your sides , palms on the earth . if you need any little assistance in this , because it is a lot of core work through here , you can place the hands underneath the hips if you need just a little bit of assistance . when i ask lauren here to engage the feet , nice deep flexion of the feet . pressing through the heels , toes to the nose . and we 're going to start with single leg raises , and we 're going to have you do three of each , on each side . starting very slowly , inhaling up the right leg . about five seconds , slowly coming up . exhaling five , four , three , two , one . inhaling up right , five , four , three , two , one . lowering down slowly , five , four , three , two , one\"\n",
    "archive = load_archive('./absummodel3.tar.gz')\n",
    "predictor = CopyNetPredictor.from_archive(archive)\n",
    "results = predictor.predict(input_string,acoustic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for x in results['predicted_tokens']:\n",
    "    print(\" \".join(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ROUGE Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Loading Examples\n",
    "from rouge import Rouge \n",
    "rouge = Rouge()\n",
    "exploretable = pd.read_pickle(\"./exploretable16052020.pkl\")\n",
    "archive = load_archive('./absummodel3.tar.gz')\n",
    "predictor = CopyNetPredictor.from_archive(archive)\n",
    "\n",
    "\n",
    "rouge_dict = {}\n",
    "for i in range(1,500):\n",
    "    print(i)\n",
    "    chosenid = exploretable.iloc[i]['id']\n",
    "    tran = exploretable.iloc[i]['tran']\n",
    "    desc = exploretable.iloc[i]['desc']\n",
    "    \n",
    "#     print(desc)\n",
    "\n",
    "#     results = predictor.predict(tran,[1,1,1])\n",
    "    summary = extractive_sum(tran,word_count=40)\n",
    "    print(summary)\n",
    "#     maximum_onef = 0 \n",
    "#     for sentence in results['predicted_tokens']:\n",
    "#         summary = \" \".join(sentence)\n",
    "#         print(summary)\n",
    "    try:\n",
    "        rouge_scores = rouge.get_scores(summary, desc)\n",
    "    except:\n",
    "        print(f\"{i} failed\")\n",
    "#         one_f = rouge_scores[0]['rouge-1']['f']\n",
    "#         if one_f > maximum_onef:\n",
    "#             maximum_rouge= rouge_scores\n",
    "#             bestsummary = summary\n",
    "    rouge_dict[chosenid] = rouge_scores\n",
    "    \n",
    "print(rouge_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize\n",
    "temp_df = pd.DataFrame.from_dict(rouge_dict, orient='index',columns=['A'])\n",
    "df_pol_ps = temp_df['A'].apply(pd.Series)\n",
    "df_pol_1 = df_pol_ps['rouge-1'].apply(pd.Series).rename(columns={\"f\": \"rouge-1-f\", \"p\": \"rouge-1-p\", \"r\": \"rouge-1-r\"})\n",
    "df_pol_2 = df_pol_ps['rouge-2'].apply(pd.Series).rename(columns={\"f\": \"rouge-2-f\", \"p\": \"rouge-2-p\", \"r\": \"rouge-2-r\"})\n",
    "df_pol_l = df_pol_ps['rouge-l'].apply(pd.Series).rename(columns={\"f\": \"rouge-l-f\", \"p\": \"rouge-l-p\", \"r\": \"rouge-l-r\"})\n",
    "rouge_df = df_pol_1.join(df_pol_2).join(df_pol_l)\n",
    "rouge_df.to_pickle(\"./rouge_df_mode1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rouge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rouge_df.sort_values(['rouge-l-f'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rouge_df.mean(axis = 0).plot.bar(x='lab', y='val',color=['blue', 'red', 'green']*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_string = \"after you 've done at least six to twelve rounds of sun salutation in sivananda yoga we start on the main practice . we will begin with leg raises . it really helps open up the core , strengthen the core , and it 's just a wonderful way to start . so i 'm going to have lauren here lay down on her back . beautiful . now bring your arms down to your sides , palms on the earth . if you need any little assistance in this , because it is a lot of core work through here , you can place the hands underneath the hips if you need just a little bit of assistance . when i ask lauren here to engage the feet , nice deep flexion of the feet . pressing through the heels , toes to the nose . and we 're going to start with single leg raises , and we 're going to have you do three of each , on each side . starting very slowly , inhaling up the right leg . about five seconds , slowly coming up . exhaling five , four , three , two , one . inhaling up right , five , four , three , two , one . lowering down slowly , five , four , three , two , one\"\n",
    "archive = load_archive('./absummodel3.tar.gz')\n",
    "predictor = CopyNetPredictor.from_archive(archive)\n",
    "results = predictor.predict(input_string,[1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for sentence in results['predicted_tokens']:\n",
    "    print(\" \".join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27),'font.size': 32, 'axes.labelsize': 16,  \n",
    "    'axes.titlesize': 24, 'xtick.labelsize': 16, 'ytick.labelsize': 16})\n",
    "colors = ['tab:blue','tab:orange','tab:green','tab:red','tab:purple']\n",
    "mode_1_df = pickle.load( open( \"rouge_df_mode1.pkl\", \"rb\" ) )\n",
    "mode_1_df.sort_values(\"rouge-1-f\",ascending=False)\n",
    "mode_1_data = mode_1_df.mean(axis = 0)\n",
    "# mode_1_data\n",
    "ax = sns.barplot(mode_1_data.index,mode_1_data.values).set( title = 'Mode 1 ROUGE Scores', xlabel = 'Summarisation Mode', ylabel = 'ROUGE Score' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "mode_2_df = pickle.load( open( \"rouge_df_mode2.pkl\", \"rb\" ) )\n",
    "mode_2_df.sort_values(\"rouge-1-f\",ascending=False)\n",
    "mode_2_data = mode_2_df.mean(axis = 0)\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27),'font.size': 32, 'axes.labelsize': 16,  \n",
    "    'axes.titlesize': 24, 'xtick.labelsize': 16, 'ytick.labelsize': 16})\n",
    "colors = ['tab:blue','tab:orange','tab:green','tab:red','tab:purple']\n",
    "\n",
    "# mode_1_data\n",
    "ax = sns.barplot(mode_2_data.index,mode_2_data.values).set( title = 'Mode 2 ROUGE Scores', xlabel = 'Summarisation Mode', ylabel = 'ROUGE Score' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "mode_3_df = pickle.load( open( \"rouge_df_model3.pkl\", \"rb\" ) )\n",
    "mode_3_df.sort_values(\"rouge-1-f\",ascending=False)\n",
    "mode_3_data = mode_3_df.mean(axis = 0)\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27),'font.size': 32, 'axes.labelsize': 16,  \n",
    "    'axes.titlesize': 24, 'xtick.labelsize': 16, 'ytick.labelsize': 16})\n",
    "colors = ['tab:blue','tab:orange','tab:green','tab:red','tab:purple']\n",
    "\n",
    "# mode_1_data\n",
    "ax = sns.barplot(mode_3_data.index,mode_3_data.values).set( title = 'Mode 3 ROUGE Scores', xlabel = 'Summarisation Mode', ylabel = 'ROUGE Score' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# mode_2_df = pickle.load( open( \"rouge_df_mode2.pkl\", \"rb\" ) )\n",
    "# mode_2_df.sort_values(\"rouge-1-f\",ascending=False)\n",
    "# mode_2_data = mode_2_df.mean(axis = 0)\n",
    "\n",
    "threeveetwo = (mode_3_data - mode_2_data)*100\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27),'font.size': 32, 'axes.labelsize': 16,  \n",
    "    'axes.titlesize': 24, 'xtick.labelsize': 16, 'ytick.labelsize': 16})\n",
    "colors = ['tab:blue','tab:orange','tab:green','tab:red','tab:purple']\n",
    "\n",
    "# mode_1_data\n",
    "ax = sns.barplot(threeveetwo.index,threeveetwo.values).set( title = 'Mode 3 vs Mode 2 ROUGE Scores', xlabel = 'Summarisation Mode', ylabel = 'ROUGE Score Percentage Change' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge \n",
    "rouge = Rouge()\n",
    "rouge_dict = {}\n",
    "for i in range(1,500):\n",
    "    print(i)\n",
    "    try:\n",
    "        youtube_id = exploretable.iloc[i]['id']\n",
    "    except:\n",
    "        continue\n",
    "    print(youtube_id)\n",
    "    tran = exploretable.iloc[i]['tran']\n",
    "    desc = exploretable.iloc[i]['desc']\n",
    "    try:\n",
    "        sentences = mode_3_summary(youtube_id,tran,desc)\n",
    "    except:\n",
    "        continue\n",
    "    maximum_onef = 0\n",
    "    for candidate in sentences:\n",
    "        try:\n",
    "            rouge_scores = rouge.get_scores(candidate, desc)\n",
    "        except:\n",
    "            print(f\"{i} failed\")\n",
    "        one_f = rouge_scores[0]['rouge-1']['f']\n",
    "        if one_f > maximum_onef:\n",
    "            maximum_rouge= rouge_scores\n",
    "    rouge_dict[youtube_id] = maximum_rouge\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame.from_dict(rouge_dict, orient='index',columns=['A'])\n",
    "df_pol_ps = temp_df['A'].apply(pd.Series)\n",
    "df_pol_1 = df_pol_ps['rouge-1'].apply(pd.Series).rename(columns={\"f\": \"rouge-1-f\", \"p\": \"rouge-1-p\", \"r\": \"rouge-1-r\"})\n",
    "df_pol_2 = df_pol_ps['rouge-2'].apply(pd.Series).rename(columns={\"f\": \"rouge-2-f\", \"p\": \"rouge-2-p\", \"r\": \"rouge-2-r\"})\n",
    "df_pol_l = df_pol_ps['rouge-l'].apply(pd.Series).rename(columns={\"f\": \"rouge-l-f\", \"p\": \"rouge-l-p\", \"r\": \"rouge-l-r\"})\n",
    "rouge_df = df_pol_1.join(df_pol_2).join(df_pol_l)\n",
    "rouge_df.to_pickle(\"./rouge_df_model3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best_svm = pickle.load( open( \"best_svm.sav\", \"rb\" ) )\n",
    "for i in best_svm.predict(X_test):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res = clf.predict(X_test)\n",
    "def avg(lst):\n",
    "    return sum(lst)/len(lst)\n",
    "\n",
    "nonzeroind = np.nonzero(y_test)[0]\n",
    "real_ones = res[nonzeroind]\n",
    "print(avg(real_ones))\n",
    "zeroind =  [idx for idx, val in enumerate(y_test) if val == 0] \n",
    "real_zeros = res[zeroind]\n",
    "print(avg(real_zeros))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Scratch area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "\n",
    "plot_a = plt.subplot(211)\n",
    "\n",
    "plot_a.plot(sig)\n",
    "plot_a.set_xlabel('Sample number (8kHz sample rate)')\n",
    "plot_a.set_ylabel('energy')\n",
    "\n",
    "plot_b = plt.subplot(212)\n",
    "plot_b.specgram(sig, NFFT=1024, Fs=sample_rate, noverlap=900)\n",
    "plot_b.set_xlabel('Time')\n",
    "plot_b.set_ylabel('Frequency')\n",
    "\n",
    "\n",
    "plt.savefig('waveform.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "exploretable = pd.read_pickle(\"./exploretable16052020.pkl\")\n",
    "row = exploretable.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpete.training.metrics\n",
    "import nlpete.data.dataset_readers\n",
    "from nlpete.models import copynet\n",
    "from allennlp.data.fields.text_field import TextFieldTensors\n",
    "from overrides import overrides\n",
    "from allennlp.models.archival import load_archive\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.data import DatasetReader\n",
    "from allennlp.common.util import JsonDict\n",
    "from allennlp.data import Instance\n",
    "from nlpete.data.dataset_readers import (\n",
    "    CopyNetDatasetReader,\n",
    ") \n",
    "from allennlp.predictors import Predictor\n",
    "import warnings\n",
    "class CopyNetPredictor(Predictor):\n",
    "    \"\"\"\n",
    "    Predictor for the CopyNet model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: Model, dataset_reader: DatasetReader) -> None:\n",
    "        super().__init__(model, dataset_reader)\n",
    "        warnings.warn(\n",
    "            \"The 'copynet' predictor has been deprecated in favor of \"\n",
    "            \"the 'seq2seq' predictor.\",\n",
    "            DeprecationWarning,\n",
    "        )\n",
    "\n",
    "    def predict(self, source: str) -> JsonDict:\n",
    "        return self.predict_json({\"source_string\": source})\n",
    "\n",
    "    @overrides\n",
    "    def _json_to_instance(self, json_dict: JsonDict) -> Instance:\n",
    "        source = json_dict[\"source_string\"]\n",
    "        return self._dataset_reader.text_to_instance(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = load_archive('./model19.tar.gz')\n",
    "predictor = CopyNetPredictor.from_archive(archive)\n",
    "predictor.predict_json({\"source_string\":\"find all wav in this directory\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = pd.read_csv('help_dayan.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_class = [1,2,3,16,17,18,31,32,33,46,47,48]\n",
    "b_class = [x+3 for x in a_class]\n",
    "c_class = [x+3 for x in b_class]\n",
    "d_class = [x+3 for x in c_class]\n",
    "e_class = [x+3 for x in d_class]\n",
    "\n",
    "def merge_on_sample(input_series):\n",
    "\n",
    "    informativeness = input_series[[0,3,6,9]].mean(axis=0)\n",
    "    understanding = input_series[[1,4,7,10]].mean(axis=0)\n",
    "    quality = input_series[[2,5,8,11]].mean(axis=0)\n",
    "    output_series = {\n",
    "        \"informativeness\":informativeness,\n",
    "        \"understanding\":understanding,\n",
    "        \"quality\":quality\n",
    "    }\n",
    "    return output_series\n",
    "\n",
    "def extract_informativeness(input_df):\n",
    "    return input_df[input_df.columns[[0,3,6,9]]].dropna().values.flatten()\n",
    "\n",
    "def extract_understanding(input_df):\n",
    "    return input_df[input_df.columns[[1,4,7,10]]].dropna().values.flatten()\n",
    "\n",
    "def extract_quality(input_df):\n",
    "    return input_df[input_df.columns[[2,5,8,11]]].dropna().values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_class_df = subj[subj.columns[a_class]]\n",
    "a_class_informativeness = (extract_informativeness(a_class_df)).mean()\n",
    "a_class_understanding = (extract_understanding(a_class_df)).mean()\n",
    "a_class_quality = (extract_quality(a_class_df))\n",
    "a_class_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_class_df = subj[subj.columns[b_class]]\n",
    "b_class_informativeness = extract_informativeness(b_class_df)\n",
    "b_class_understanding = extract_understanding(b_class_df)\n",
    "b_class_quality = extract_quality(b_class_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_class_df = subj[subj.columns[c_class]]\n",
    "c_class_informativeness = extract_informativeness(c_class_df)\n",
    "c_class_understanding = extract_understanding(c_class_df)\n",
    "c_class_quality = extract_quality(c_class_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_class_df = subj[subj.columns[d_class]]\n",
    "d_class_informativeness = extract_informativeness(d_class_df)\n",
    "d_class_understanding = extract_understanding(d_class_df)\n",
    "d_class_quality = extract_quality(d_class_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_class_df = subj[subj.columns[e_class]]\n",
    "e_class_informativeness = extract_informativeness(e_class_df)\n",
    "e_class_understanding = extract_understanding(e_class_df)\n",
    "e_class_quality = extract_quality(e_class_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stats.f_oneway(a_class_quality,b_class_quality,c_class_quality,d_class_quality,e_class_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.f_oneway(b_class_informativeness, c_class_informativeness)\n",
    "# stats.f_oneway(b_class_understanding, c_class_understanding)\n",
    "stats.f_oneway(b_class_quality, c_class_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "data = [a_class_informativeness,b_class_informativeness, c_class_informativeness,d_class_informativeness,e_class_informativeness]\n",
    "colors = ['tab:blue','tab:orange','tab:green','tab:red','tab:purple']\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "fig.suptitle('Informativeness MOS scores', fontsize=30)\n",
    "ax.set_ylabel('MOS Score',fontsize=20)\n",
    "ax.set_xlabel('Summarisation Mode',fontsize=20)\n",
    "box_dict = ax.boxplot(data, patch_artist=True,  showmeans=True)\n",
    "for item in ['boxes', 'fliers', 'medians', 'means']:\n",
    "    for sub_item,color in zip(box_dict[item], colors):\n",
    "        plt.setp(sub_item, color=color)\n",
    "# whiskers and caps have to be treated separately since there are two of each for each plot\n",
    "for item in ['whiskers', 'caps']:\n",
    "    for sub_items,color in zip(zip(box_dict[item][::2],box_dict[item][1::2]),colors):\n",
    "        plt.setp(sub_items, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "data = [a_class_understanding,b_class_understanding, c_class_understanding,d_class_understanding,e_class_understanding]\n",
    "colors = ['tab:blue','tab:orange','tab:green','tab:red','tab:purple']\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "fig.suptitle('Understanding MOS scores', fontsize=30)\n",
    "ax.set_ylabel('MOS Score',fontsize=20)\n",
    "ax.set_xlabel('Summarisation Mode',fontsize=20)\n",
    "box_dict = ax.boxplot(data, patch_artist=True,  showmeans=True)\n",
    "for item in ['boxes', 'fliers', 'medians', 'means']:\n",
    "    for sub_item,color in zip(box_dict[item], colors):\n",
    "        plt.setp(sub_item, color=color)\n",
    "# whiskers and caps have to be treated separately since there are two of each for each plot\n",
    "for item in ['whiskers', 'caps']:\n",
    "    for sub_items,color in zip(zip(box_dict[item][::2],box_dict[item][1::2]),colors):\n",
    "        plt.setp(sub_items, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "data = [a_class_quality,b_class_quality, c_class_quality,d_class_quality,e_class_quality]\n",
    "colors = ['tab:blue','tab:orange','tab:green','tab:red','tab:purple']\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "fig.suptitle('Quality MOS scores', fontsize=30)\n",
    "ax.set_ylabel('MOS Score',fontsize=20)\n",
    "ax.set_xlabel('Summarisation Mode',fontsize=20)\n",
    "box_dict = ax.boxplot(data, patch_artist=True,  showmeans=True)\n",
    "for item in ['boxes', 'fliers', 'medians', 'means']:\n",
    "    for sub_item,color in zip(box_dict[item], colors):\n",
    "        plt.setp(sub_item, color=color)\n",
    "# whiskers and caps have to be treated separately since there are two of each for each plot\n",
    "for item in ['whiskers', 'caps']:\n",
    "    for sub_items,color in zip(zip(box_dict[item][::2],box_dict[item][1::2]),colors):\n",
    "        plt.setp(sub_items, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('FYPenv': conda)",
   "language": "python",
   "name": "python37564bitfypenvconda60f1d227ddc44fa2a53c258bf33a3203"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
